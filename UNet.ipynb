{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BvhnplhGrigd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vC8GlkHgrmJu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sK-9vYBWrmL4"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import init #used for initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nvNMG-79rmOd"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels,out_channels,stride=1,padding=1,bias=True,groups=1):\n",
    "    return nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=padding,bias=bias,groups=groups)\n",
    "\n",
    "def upconv2x2(in_channels,out_channels,mode='transpose'):\n",
    "    if mode=='transpose':\n",
    "        return nn.ConvTranspose2d(in_channels,out_channels,kernel_size=2,stride=2)\n",
    "    else:\n",
    "        return nn.Sequential(nn.Upsample(mode='Bilinear',scale_factor=2),conv1x1(in_channels,out_channels))\n",
    "    \n",
    "def conv1x1(in_channels,out_channels,groups=1):\n",
    "    return nn.Conv2d(in_channels,out_channels,kernel_size=1,groups=groups,stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nv0b1sYvrmRD"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Downconv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,pooling=True):\n",
    "        super(Downconv,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.pooling=pooling\n",
    "    \n",
    "        self.conv1=conv3x3(self.in_channels,self.out_channels)\n",
    "        self.conv2=conv3x3(self.out_channels,self.out_channels)\n",
    "    \n",
    "        if self.pooling:\n",
    "            self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=F.relu(self.conv2(x))\n",
    "        before_pool=x\n",
    "        if self.pooling:\n",
    "            x=self.pool(x)\n",
    "        return x,before_pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OnH5fHwvrmT3"
   },
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,merge_mode='concat',up_mode='transpose'):\n",
    "        super(UpConv,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.merge_mode=merge_mode\n",
    "        self.up_mode=up_mode\n",
    "        \n",
    "        self.upconv=upconv2x2(self.in_channels,self.out_channels,mode=self.up_mode)\n",
    "        \n",
    "        if self.merge_mode=='concat':\n",
    "            self.conv1=conv3x3(2*self.out_channels,out_channels)\n",
    "        else:\n",
    "            self.conv1=conv3x3(self.out_channels,self.out_channels)\n",
    "        self.conv2=conv3x3(self.out_channels,self.out_channels)    \n",
    "        \n",
    "    def forward(self,from_down,from_up):\n",
    "        #from up: tensor from decoder path\n",
    "        #from_down tensor to concatenate which is the before_pool tensor in encoder arch\n",
    "        from_up=self.upconv(from_up)\n",
    "        if self.merge_mode=='concat':\n",
    "            x=torch.cat((from_up,from_down),1) #1 gives the dimension to concat along\n",
    "        else:\n",
    "            x=from_up+from_down\n",
    "            \n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=F.relu(self.conv2(x))\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pgK7-9SLrmWf"
   },
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self,num_classes,in_channels=3,depth=5,start_filts=64,up_mode='transpose',merge_mode='concat'):\n",
    "        \n",
    "        super(Unet,self).__init__()\n",
    "        if up_mode in ('transpose','upsample'):\n",
    "            self.up_mode=up_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"upsampling. Only \\\"transpose\\\" and \"\n",
    "                             \"\\\"upsample\\\" are allowed.\".format(up_mode))\n",
    "            \n",
    "        \n",
    "        if merge_mode in ('concat','add'):\n",
    "            self.merge_mode=merge_mode\n",
    "        else:\n",
    "            raise ValueError(\"\\\"{}\\\" is not a valid mode for \"\n",
    "                             \"merging. Only \\\"concat\\\" and \"\n",
    "                             \"\\\"add\\\" are allowed.\".format(merge_mode))\n",
    "        \n",
    "        if self.merge_mode=='add' and self.up_mode=='upsample':\n",
    "            raise ValueError(\"up_mode \\\"upsample\\\" is incompatible \"\n",
    "                             \"with merge_mode \\\"add\\\" at the moment \"\n",
    "                             \"because it doesn't make sense to use \"\n",
    "                             \"nearest neighbour to reduce \"\n",
    "                             \"depth channels (by half).\")\n",
    "            \n",
    "        self.num_classes=num_classes\n",
    "        self.in_channels=in_channels\n",
    "        self.depth=depth\n",
    "        self.start_filts=start_filts\n",
    "        \n",
    "        self.down_convs=[]\n",
    "        self.up_convs=[]\n",
    "        \n",
    "        #create the encoder pathway and add to a list\n",
    "        for i in range(depth):\n",
    "            ins=self.in_channels if i==0 else outs\n",
    "            outs=self.start_filts*(2**i)\n",
    "            pooling=True if i<(depth-1) else False\n",
    "\n",
    "            downconv=Downconv(ins,outs,pooling=pooling) \n",
    "            self.down_convs.append(downconv) #list of modules in the down path\n",
    "            \n",
    "        \n",
    "        #create the decoder pathway and add to a list\n",
    "        for i in range(depth-1):\n",
    "            ins=outs\n",
    "            outs=ins//2\n",
    "            up_conv=UpConv(ins,outs,up_mode=up_mode,merge_mode=merge_mode)\n",
    "            self.up_convs.append(up_conv) #list of modules in the up path \n",
    "            \n",
    "        self.conv_final=conv1x1(outs,num_classes)\n",
    "            \n",
    "        #add the list of modules to the current module\n",
    "        self.down_convs=nn.ModuleList(self.down_convs)\n",
    "        self.up_convs=nn.ModuleList(self.up_convs)\n",
    "            \n",
    "        self.reset_params()\n",
    "            \n",
    "    #def weight_init(m):\n",
    "        #if isinstance(m,nn.Conv2d):\n",
    "            #init.xavier_normal(m.weight.double())\n",
    "            #init.constant(m.bias,0)\n",
    "            \n",
    "    def reset_params(self):\n",
    "        for i,m in enumerate(self.modules()):#self.modules returns an overall iterator over the modules of the net\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                init.xavier_normal_(m.weight).double()\n",
    "                init.constant_(m.bias,0)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        encoder_outs=[]\n",
    "        \n",
    "        for i,module in enumerate(self.down_convs):\n",
    "            x,before_pool=module(x)\n",
    "            encoder_outs.append(before_pool)\n",
    "            \n",
    "        for i,module in enumerate(self.up_convs): \n",
    "            before_pool=encoder_outs[-(i+2)]\n",
    "            x=module(before_pool,x)\n",
    "        \n",
    "        #no softmax but 1x1 conv is used for generating labels\n",
    "        x=self.conv_final(x)\n",
    "        return x\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1EYfNHnrmZE",
    "outputId": "7771fc30-c43a-467b-9e22-de2bcbbdb82f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    #testing on a random input\n",
    "    model=Unet(3,depth=5,merge_mode='concat')\n",
    "    x=Variable(torch.FloatTensor(np.random.random((1,3,320,320))))\n",
    "    out = model(x)\n",
    "    loss=torch.sum(out)\n",
    "    loss.backward()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfErXpsArmby",
    "outputId": "2f89e81e-4cfc-466b-8011-81c50b7994f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1102.5709, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pkclqgfLrmel"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pyqEAHJgrmhY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KvyDTCF9rmkA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ejuap320rmms"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QW8VwKrWeb3k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xq8EGekrmqM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
